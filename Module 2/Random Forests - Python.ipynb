{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests - Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Welcome to Lab 2c of Machine Learning with Python.</b>\n",
    "<p> <b>Machine Learning is a form of artificial intelligence (AI), where the system can \"learn\" without explicitly being coded</b></p>\n",
    "\n",
    "In this lab exercise, you will learn some popular machine learning algorithms. For <b>supervised learning</b>, we will discuss <b>decision trees</b> and <b>random forests</b>. In <b>unsupervised learning</b>, we will discuss <b>k-means clustering</b>, <b>agglomerative hierarchical clustering</b>, and <b>density-based clustering</b> or <b>DBSCAN</b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Notebook Commands Reminders:\n",
    "<ul>\n",
    "    <li>Run a cell: CTRL + ENTER</li>\n",
    "    <li>Create a cell above a cell: a</li>\n",
    "    <li>Create a cell below a cell: b</li>\n",
    "    <li>Change a cell to Markdown: m</li>\n",
    "    \n",
    "    <li>Change a cell to code: y</li>\n",
    "</ul>\n",
    "\n",
    "<b> If you are interested in more keyboard shortcuts, go to Help -> Keyboard Shortcuts </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Random Forests with RandomForestClassifier</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the <b>RandomForestClassifier</b> class from <b>sklearn.ensemble</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create an instance of the <b>RandomForestClassifier()</b> called <b>skullsForest</b>, where the forest has <b>10 decision tree estimators</b> (<i>n_estimators=10</i>) and the <b>criterion is entropy</b> (<i>criterion=\"entropy\"</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "my_data = pandas.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/skulls.csv\", delimiter=\",\")\n",
    "X = my_data.drop(my_data.columns[[0,1]], axis=1).values\n",
    "y = my_data[\"epoch\"]\n",
    "\n",
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "skullsForest = RandomForestClassifier(criterion = \"entropy\", n_estimators=10)\n",
    "skullsForest.fit(X_trainset, y_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's use the same <b>X_trainset</b>, <b>y_trainset</b> datasets that we made when dealing with the <b>Decision Trees</b> above to fit <b>skullsForest</b>.\n",
    "<br> <br>\n",
    "\n",
    "<b>Note</b>: Make sure you have ran through the Decision Trees section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a variable called <b>predForest</b> using a predict on <b>X_testset</b> with <b>skullsForest</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predForest = skullsForest.predict(X_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print out <b>predForest</b> and <b>y_testset</b> if you want to visually compare the prediction to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c200BC' 'c200BC' 'cAD150' 'c200BC' 'c200BC' 'c4000BC' 'c200BC' 'c4000BC'\n",
      " 'c4000BC' 'c3300BC' 'c1850BC' 'c1850BC' 'c4000BC' 'c4000BC' 'c200BC'\n",
      " 'cAD150' 'c200BC' 'c200BC' 'c1850BC' 'c3300BC' 'c200BC' 'c1850BC'\n",
      " 'c200BC' 'c200BC' 'c1850BC' 'c200BC' 'c1850BC' 'c3300BC' 'c1850BC'\n",
      " 'c3300BC' 'c200BC' 'c4000BC' 'cAD150' 'cAD150' 'cAD150' 'c3300BC'\n",
      " 'c3300BC' 'c1850BC' 'cAD150' 'c1850BC' 'c200BC' 'c3300BC' 'c1850BC'\n",
      " 'c200BC' 'c1850BC']\n",
      "5      c4000BC\n",
      "70     c1850BC\n",
      "112     c200BC\n",
      "91      c200BC\n",
      "41     c3300BC\n",
      "69     c1850BC\n",
      "36     c3300BC\n",
      "85     c1850BC\n",
      "42     c3300BC\n",
      "35     c3300BC\n",
      "73     c1850BC\n",
      "45     c3300BC\n",
      "57     c3300BC\n",
      "147     cAD150\n",
      "9      c4000BC\n",
      "109     c200BC\n",
      "126     cAD150\n",
      "148     cAD150\n",
      "7      c4000BC\n",
      "29     c4000BC\n",
      "133     cAD150\n",
      "141     cAD150\n",
      "149     cAD150\n",
      "49     c3300BC\n",
      "25     c4000BC\n",
      "79     c1850BC\n",
      "146     cAD150\n",
      "95      c200BC\n",
      "75     c1850BC\n",
      "13     c4000BC\n",
      "119     c200BC\n",
      "12     c4000BC\n",
      "94      c200BC\n",
      "53     c3300BC\n",
      "34     c3300BC\n",
      "113     c200BC\n",
      "33     c3300BC\n",
      "4      c4000BC\n",
      "144     cAD150\n",
      "3      c4000BC\n",
      "62     c1850BC\n",
      "59     c3300BC\n",
      "32     c3300BC\n",
      "132     cAD150\n",
      "78     c1850BC\n",
      "Name: epoch, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(predForest)\n",
    "print(y_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the accuracy of our model. <br>\n",
    "\n",
    "Note: Make sure you have metrics imported from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForests's Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.2222222222222222)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(\"RandomForests's Accuracy: \"), metrics.accuracy_score(y_testset, predForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see what trees are in our <b> skullsForest </b> variable by using the <b> .estimators_ </b> attribute. This attribute is indexable, so we can look at any individual tree we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1949699857, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=2113252142, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1419995296, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1610689714, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=120275305, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1052312312, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1748966972, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=703656319, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1698521583, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=582037343, splitter='best')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skullsForest.estimators_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
